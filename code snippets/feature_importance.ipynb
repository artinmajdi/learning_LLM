{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP vs. Built-in Feature Importance for American Airlines Customer Satisfaction Analysis\n",
    "\n",
    "This notebook demonstrates SHAP vs. Built-in Feature Importance for a mock American Airlines Customer Satisfaction Analysis scenario.\n",
    "\n",
    "It implements a simplified version of the concepts discussed in feature_importance_shap_vs_builtin.md, showcasing:\n",
    "- Training an XGBoost model on synthetic customer satisfaction data.\n",
    "- Extracting built-in feature importances.\n",
    "- Calculating and visualizing SHAP values for global and local explanations, and feature interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Customer Satisfaction Data\n",
    "\n",
    "First, we'll create synthetic data that resembles airline customer satisfaction features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def generate_synthetic_data(num_samples=1000):\n",
    "    \"\"\"Generates synthetic data resembling airline customer satisfaction features.\"\"\"\n",
    "    np.random.seed(42) # for reproducibility\n",
    "    data                           = pd.DataFrame()\n",
    "    data['FlightDelayMinutes']     = np.random.lognormal(mean=3, sigma=0.8, size=num_samples).astype(int)\n",
    "    data['FlightDelayMinutes']     = np.clip(data['FlightDelayMinutes'], 0, 300) # Cap delays\n",
    "    data['IsEliteStatus']          = np.random.choice([0, 1], size=num_samples, p=[0.8, 0.2])\n",
    "    data['SeatComfort']            = np.random.randint(1, 6, size=num_samples) # 1-5 scale\n",
    "    data['InflightEntertainment']  = np.random.randint(1, 6, size=num_samples) # 1-5 scale\n",
    "    data['StaffAttitude']          = np.random.randint(1, 6, size=num_samples) # 1-5 scale\n",
    "    data['ProactiveCommunication'] = np.random.choice([0, 1], size=num_samples, p=[0.6, 0.4])\n",
    "\n",
    "    # Create a synthetic target: CustomerSatisfaction (1=Satisfied, 0=Dissatisfied)\n",
    "    # Satisfaction decreases with delays, increases with other positive factors\n",
    "    satisfaction_score = (\n",
    "        -0.01 * data['FlightDelayMinutes'] +\n",
    "        1.0 * data['IsEliteStatus'] +\n",
    "        0.5 * data['SeatComfort'] +\n",
    "        0.4 * data['InflightEntertainment'] +\n",
    "        0.6 * data['StaffAttitude'] +\n",
    "        0.8 * data['ProactiveCommunication'] +\n",
    "        np.random.normal(0, 1.5, num_samples) # Add some noise\n",
    "    )\n",
    "    data['CustomerSatisfaction'] = (satisfaction_score > np.median(satisfaction_score)).astype(int)\n",
    "    return data\n",
    "\n",
    "print(\"Generating synthetic customer satisfaction data...\")\n",
    "df = generate_synthetic_data()\n",
    "print(\"Sample of generated data:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Model Training\n",
    "\n",
    "Now we'll split the data into training and testing sets, and train an XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "X = df.drop('CustomerSatisfaction', axis=1)\n",
    "y = df['CustomerSatisfaction']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training XGBoost model...\")\n",
    "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Built-in GBDT Feature Importance\n",
    "\n",
    "XGBoost provides built-in feature importance metrics. We'll examine the 'gain' importance type, which reflects the improvement in accuracy brought by each feature.\n",
    "\n",
    "**Methodology**: Typically measures how often a feature is used in trees (e.g., 'weight') or its average gain ('gain').\n",
    "\n",
    "**Output**: Global importance scores only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# XGBoost offers different importance types: 'weight', 'gain', 'cover', 'total_gain', 'total_cover'\n",
    "# 'gain' is often a good default as it reflects the improvement in accuracy brought by a feature.\n",
    "built_in_importance = model.get_booster().get_score(importance_type='gain')\n",
    "if not built_in_importance:\n",
    "    # Fallback if 'gain' is not available or model is simple (e.g., single tree)\n",
    "    built_in_importance_values = model.feature_importances_\n",
    "    built_in_importance = {X_train.columns[i]: built_in_importance_values[i] for i in range(len(X_train.columns))}\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_importance = sorted(built_in_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top built-in feature importances (by gain):\")\n",
    "for feature, score in sorted_importance:\n",
    "    print(f\"- {feature}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "xgb.plot_importance(model, importance_type='gain', max_num_features=10, title='Built-in Feature Importance (Gain)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('builtin_feature_importance.png')\n",
    "print(\"Saved built-in feature importance plot to 'builtin_feature_importance.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of Built-in Feature Importance for American Airlines\n",
    "\n",
    "- **Computational efficiency**: Faster for initial exploration, especially with large datasets.\n",
    "- **Implementation simplicity**: Readily available in GBDT packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SHAP (SHapley Additive exPlanations) Values\n",
    "\n",
    "SHAP values provide a more nuanced view of feature importance based on cooperative game theory.\n",
    "\n",
    "**Methodology**: Based on cooperative game theory, fairly distributes prediction credit.\n",
    "\n",
    "**Output**: Local (per-prediction) and global (aggregated) importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# SHAP works well with tree-based models like XGBoost\n",
    "explainer = shap.Explainer(model, X_train) # Using X_train as background data for TreeExplainer\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Correctly access SHAP values for a binary classification model\n",
    "# For XGBClassifier, explainer(X_test) returns an Explanation object.\n",
    "# shap_values.values will be an array where for binary classification,\n",
    "# if it's (num_samples, num_features, num_classes), we usually use the values for the positive class.\n",
    "# If it's (num_samples, num_features), it's often already for the positive class.\n",
    "# Let's inspect the shape\n",
    "\n",
    "# For binary classification with XGBoost, shap_values often has shape (n_samples, n_features)\n",
    "# representing SHAP values for the positive class. If it has 2 classes, use shap_values_for_class_1\n",
    "\n",
    "if len(shap_values.values.shape) == 3: # (samples, features, classes)\n",
    "    shap_values_for_class_1 = shap_values.values[:, :, 1] # Assuming class 1 is 'Satisfied'\n",
    "    expected_value_class_1 = explainer.expected_value[1]\n",
    "else: # (samples, features)\n",
    "    shap_values_for_class_1 = shap_values.values\n",
    "    expected_value_class_1 = explainer.expected_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. SHAP Global Feature Importance (Summary Bar Plot)\n",
    "\n",
    "This shows the mean absolute SHAP value for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "shap.summary_plot(shap_values_for_class_1, X_test, plot_type=\"bar\", show=False)\n",
    "plt.title('SHAP Global Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_global_importance_bar.png')\n",
    "print(\"Saved SHAP global importance bar plot to 'shap_global_importance_bar.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. SHAP Summary Plot (Beeswarm)\n",
    "\n",
    "This shows the distribution of SHAP values for each feature, with color indicating the feature value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "shap.summary_plot(shap_values_for_class_1, X_test, show=False)\n",
    "plt.title('SHAP Summary Plot (Beeswarm)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_summary_beeswarm.png')\n",
    "print(\"Saved SHAP summary beeswarm plot to 'shap_summary_beeswarm.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. SHAP Local Explanations (Waterfall plot for a single prediction)\n",
    "\n",
    "This shows how each feature contributes to the prediction for a single passenger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "passenger_index = 0 # Explain the first passenger in the test set\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "# Create an Explanation object for the single instance for waterfall plot\n",
    "individual_shap_values = shap.Explanation(\n",
    "    values=shap_values_for_class_1[passenger_index,:],\n",
    "    base_values=expected_value_class_1,\n",
    "    data=X_test.iloc[passenger_index,:],\n",
    "    feature_names=X_test.columns\n",
    ")\n",
    "shap.plots.waterfall(individual_shap_values, max_display=10, show=False)\n",
    "plt.title(f'SHAP Waterfall Plot for Passenger {passenger_index} (Prediction: {model.predict(X_test.iloc[[passenger_index]])[0]})')\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_local_waterfall.png')\n",
    "print(\"Saved SHAP local waterfall plot to 'shap_local_waterfall.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4d. SHAP Dependence Plot (Interaction Effects)\n",
    "\n",
    "This shows how the SHAP value for one feature depends on the value of another feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "feature_to_plot = 'FlightDelayMinutes'\n",
    "interaction_feature = 'IsEliteStatus'\n",
    "print(f\"SHAP Dependence Plot (Interaction of '{feature_to_plot}' with '{interaction_feature}'):\")\n",
    "\n",
    "plt.figure()\n",
    "shap.dependence_plot(\n",
    "    feature_to_plot,\n",
    "    shap_values_for_class_1,\n",
    "    X_test,\n",
    "    interaction_index=interaction_feature,\n",
    "    show=False\n",
    ")\n",
    "plt.title(f'SHAP Dependence: {feature_to_plot} (Interaction with {interaction_feature})')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'shap_dependence_{feature_to_plot}_vs_{interaction_feature}.png')\n",
    "print(f\"Saved SHAP dependence plot to 'shap_dependence_{feature_to_plot}_vs_{interaction_feature}.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of SHAP for American Airlines' Customer Satisfaction Analysis\n",
    "\n",
    "- **Consistency across models**: Provides consistent interpretation.\n",
    "- **Direction of impact**: Shows if a feature positively or negatively affects satisfaction (e.g., beeswarm plot).\n",
    "- **Interaction detection**: Reveals how features interact (e.g., dependence plots).\n",
    "- **Local explanations**: Provides passenger-specific insights (e.g., waterfall plots) for personalized service.\n",
    "- **Regulatory alignment & Trust building**: More defensible and intuitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Practical Application at American Airlines (Hybrid Approach)\n",
    "\n",
    "### Recommended Approach\n",
    "\n",
    "1. **Use built-in importance for initial exploration and model iteration:**\n",
    "   - Quick feedback during model development.\n",
    "   - Faster processing for high-level trend analysis.\n",
    "\n",
    "2. **Use SHAP for deeper operational insights and action planning:**\n",
    "   - Detailed analysis of how service disruptions affect different customer segments.\n",
    "   - Generating personalized explanations for customer service agents.\n",
    "   - Root cause analysis for satisfaction outliers.\n",
    "\n",
    "### Specific American Airlines use cases for SHAP (as demonstrated by the plots):\n",
    "\n",
    "- Understanding how elite status moderates negative impact of delays (via dependence plots).\n",
    "- Quantifying the effect of proactive communication during IRROPs (via summary/beeswarm plots)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
